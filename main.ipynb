{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img,thresh=1):\n",
    "    new_img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    __,new_img = cv2.threshold(new_img,170,255,cv2.THRESH_BINARY_INV)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    new_img = cv2.dilate(new_img,kernel,iterations = 2)\n",
    "    new_img = cv2.erode(new_img,kernel,iterations=1)\n",
    "    return new_img\n",
    "def getMeanArea(contours):\n",
    "    meanArea=0\n",
    "    for contour in contours: meanArea+=cv2.contourArea(contour)\n",
    "    meanArea=(meanArea)/len(contours)\n",
    "    return meanArea  \n",
    "def getRatioArea(contours):\n",
    "    meanArea=0\n",
    "    for contour in contours: meanArea+=cv2.contourArea(contour)\n",
    "    cnsSorted = sorted(contours, key=lambda x:cv2.contourArea(x), reverse = True)\n",
    "    ratioArea = cv2.contourArea(cnsSorted[0])/meanArea\n",
    "    return ratioArea\n",
    "def purify(img):\n",
    "    img=cv2.copyMakeBorder(img,32,32,32,32,cv2.BORDER_CONSTANT)\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    meanArea=getMeanArea(contours)\n",
    "    nlabels,labels,stats,centroids=cv2.connectedComponentsWithStats(img,None,None,None,8,cv2.CV_32S)\n",
    "    areas=stats[1:,cv2.CC_STAT_AREA]\n",
    "    result=np.zeros((labels.shape),np.uint8)\n",
    "    for i in range(nlabels-1):\n",
    "        if areas[i]>=0.1*meanArea:\n",
    "            result[labels==i+1]=255\n",
    "    high=max(result.shape[0],result.shape[1])\n",
    "    if high==result.shape[0]:\n",
    "        dif=(high-result.shape[1])//2\n",
    "        result=cv2.copyMakeBorder(result,0,0,dif,dif,cv2.BORDER_CONSTANT,value=0)\n",
    "    else:\n",
    "        dif=(high-result.shape[1])//2\n",
    "        result=cv2.copyMakeBorder(result,dif,dif,0,0,cv2.BORDER_CONSTANT,value=0)\n",
    "    return cv2.resize(result,(28,28),interpolation=cv2.INTER_AREA)\n",
    "def extract_character(image, recursion = 0):\n",
    "    thresh = cv2.copyMakeBorder(image, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
    "    pad=5\n",
    "    thresh=cv2.GaussianBlur(thresh, (3,3), 0)\n",
    "    ret,thresh=cv2.threshold(thresh,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    kernel1 = np.ones((3,3), np.uint8)\n",
    "    thresh = cv2.dilate(thresh, kernel1, iterations = 1)    \n",
    "    if(recursion<2):\n",
    "    \tthresh2 = cv2.erode(thresh, np.ones((2,2), np.uint8), iterations = 2)\n",
    "    \tthresh2 = scipy.ndimage.median_filter(thresh2, (5, 1)) # remove line noise\n",
    "    \tthresh2 = scipy.ndimage.median_filter(thresh2, (1, 5)) # weaken circle noise\n",
    "    \tthresh2 = scipy.ndimage.median_filter(thresh2, (5, 1)) # remove line noise\n",
    "    \tthresh2 = scipy.ndimage.median_filter(thresh2, (1, 5)) # weaken circle noise\n",
    "    \tcontours1, hierarchy = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    else: contours1, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    coords=[]\n",
    "    count=0\n",
    "    ratioArea = getRatioArea(contours1)\n",
    "    if(ratioArea<0.3 or recursion>1): kernel2 = np.ones((2,2), np.uint8)\n",
    "    elif(ratioArea>0.85 and recursion<1): kernel2 = np.ones((5,5), np.uint8)\n",
    "    else: kernel2 = np.ones((3,3), np.uint8)\n",
    "    if(ratioArea > 0.3 and recursion<2):\n",
    "    \tthresh = cv2.erode(thresh, kernel2, iterations = 2)\n",
    "    \tthresh = scipy.ndimage.median_filter(thresh, (5, 1)) # remove line noise\n",
    "    \tthresh = scipy.ndimage.median_filter(thresh, (1, 5)) # weaken circle noise\n",
    "    \tthresh = scipy.ndimage.median_filter(thresh, (5, 1)) # remove line noise\n",
    "    \tthresh = scipy.ndimage.median_filter(thresh, (1, 5)) # weaken circle noise\n",
    "    thresh = cv2.dilate(thresh, kernel1, iterations = 1)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    coords=[]\n",
    "    count=0\n",
    "    meanArea=getMeanArea(contours)\n",
    "    for contour in contours:\n",
    "        (x,y,w,h)=cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour)>0.05*meanArea:\n",
    "            if w / h > 1.25:  #Split it in half into two letter regions\n",
    "                half_width = int(w / 2)\n",
    "                coords.append((x, y, half_width, h))\n",
    "                coords.append((x + half_width, y, half_width, h))\n",
    "                count=count+2\n",
    "            else:  \n",
    "                coords.append((x, y, w, h))\n",
    "                count=count+1\n",
    "    coords=sorted(coords,key=lambda x: x[0])\n",
    "    img_paths=[]\n",
    "    if(count >7 and recursion <3):\n",
    "    \timg_paths_array = extract_character(image, recursion + 1)\n",
    "    \treturn img_paths_array\n",
    "    else:\n",
    "    \tfor i in range(count):\n",
    "        \tresult=purify(thresh[coords[i][1]:coords[i][1]+coords[i][3],coords[i][0]:coords[i][0]+coords[i][2]])\n",
    "        \tfilename='character'+str(i)+'.jpg'\n",
    "        \tcv2.imwrite(filename,cv2.bitwise_not(result))\n",
    "        \timg_paths.append(filename)\n",
    "    \treturn np.array(img_paths)\n",
    "def crop_captcha(test):\n",
    "    u = np.where((np.sum(test,axis=1)/np.sum(test))!=0)[0].min()\n",
    "    d = np.where((np.sum(test,axis=1)/np.sum(test))!=0)[0].max()\n",
    "    l = np.where((np.sum(test, axis=0)/np.sum(test))!=0)[0].min()\n",
    "    r = np.where((np.sum(test, axis=0)/np.sum(test))!=0)[0].max()\n",
    "    return test[u:d,l:r]\n",
    "def segment(img, thresh1=0.001, thresh2=1.2):\n",
    "  test = img.copy()\n",
    "  arr = np.where((np.sum(test, axis=0)/np.sum(test)) < thresh1/100)[0]\n",
    "  i = 0\n",
    "  l,r = list(), list()\n",
    "  while(i<len(arr)):\n",
    "    l.append(arr[i])\n",
    "    i+=1\n",
    "    while(i<(len(arr)-1) and (arr[i+1]==arr[i]+1 or arr[i+1]==arr[i])):\n",
    "      i+=1\n",
    "    r.append(arr[i])\n",
    "    i+=1\n",
    "  ret = list()\n",
    "  prev = 0\n",
    "  for i in range(len(l)):\n",
    "    x = (l[i]+r[i])//2\n",
    "    \n",
    "    if (x!=prev): \n",
    "      ret.append(test[:, prev:x])\n",
    "    # plt.imshow(ret)\n",
    "    prev = x\n",
    "  ret.append(test[:, prev:])\n",
    "  return ret\n",
    "def add_border(img, shape):\n",
    "  if img.shape[0] > img.shape[1]:\n",
    "    x = (img.shape[0]-img.shape[1])\n",
    "    y = x//2\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top = 10,\n",
    "        bottom = 10,\n",
    "        left = y+10,\n",
    "        right = x-y+10,\n",
    "        borderType = cv2.BORDER_CONSTANT,\n",
    "        value = 0 \n",
    "    )\n",
    "  else:\n",
    "    x = (img.shape[1]-img.shape[0])\n",
    "    y = x//2\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top = y+10,\n",
    "        bottom = x-y+10,\n",
    "        left = 10,\n",
    "        right = 10,\n",
    "        borderType = cv2.BORDER_CONSTANT,\n",
    "        value = 0 \n",
    "    )\n",
    "  img = cv2.resize(img, (shape,shape), interpolation=cv2.INTER_CUBIC)#\n",
    "  return img\n",
    "def centre_img(test):\n",
    "  test = cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)\n",
    "  # plt.imshow(test)\n",
    "  M = cv2.moments(test, binaryImage=True)\n",
    "  if M[\"m00\"] != 0:\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "  else:\n",
    "    cX, cY = 0, 0\n",
    "  height, width = test.shape[:2]\n",
    "  translation_matrix = np.array([\n",
    "    [1, 0, width//2-cX],\n",
    "    [0, 1, height//2-cY],\n",
    "  ], dtype=np.float32)\n",
    "  translated_image = cv2.warpAffine(src=test, M = translation_matrix, dsize=(width, height))\n",
    "  return translated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emodel = tf.keras.models.load_model('jaishreeram_emoji.h5')\n",
    "lmodel = tf.keras.models.load_model('jaishreeram_letters.h5',compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_solver(path):\n",
    "    classes=' ABCDEFGHIJKLMNOPQRSTUVWXYZ01234567891234567'\n",
    "    image = cv2.imread(path)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    img_paths=extract_character(image)\n",
    "    output=' '\n",
    "    for i in img_paths:\n",
    "        m=[]\n",
    "        img=cv2.imread(i,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.bitwise_not(img)\n",
    "        # cv2.imshow('img',img)\n",
    "        # cv2.waitKey(0)\n",
    "        img=np.reshape(img,(28,28,1))/255\n",
    "        m.append(img)\n",
    "        m=np.array(m)\n",
    "        result=np.argmax(lmodel.predict(m))\n",
    "        output+=classes[result]\n",
    "\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_solver(path):\n",
    "    ans = \"\"\n",
    "    image = cv2.imread(path)\n",
    "    image = preprocess_img(image)\n",
    "    image = crop_captcha(image)\n",
    "    image_list = list()\n",
    "    for imgs in segment(image,thresh2=3):\n",
    "        image_list.append(imgs)\n",
    "    \n",
    "    for test in image_list:\n",
    "        testEmoji = add_border(test,300)\n",
    "        # plt.imshow(test)\n",
    "        testEmoji = centre_img(testEmoji)\n",
    "        # plt.imshow(test)\n",
    "        testEmoji = np.expand_dims(testEmoji.astype(np.float32)/255, [-1,0])\n",
    "        emojiArray = emodel.predict(testEmoji)\n",
    "        emojiArray = emojiArray.reshape(emojiArray.shape[1])\n",
    "        ans  = ans + str(np.argmax(emojiArray)+1)\n",
    "        # cv2.imshow('img',testEmoji.reshape(300,300))\n",
    "        # cv2.waitKey(0)\n",
    "        \n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "#pass file path to check letters\n",
    "letter_solver('test1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "#pass file path to check emojis\n",
    "emoji_solver('test9.jpg')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e81750055869a9c528b912dda5e0a09deab09cbbe0089ea6eb33a589a5fa0ca0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
